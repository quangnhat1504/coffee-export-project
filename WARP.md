# WARP.md

This file provides guidance to WARP (warp.dev) when working with code in this repository.

## Project Overview

**Vietnam Coffee Data Portal** - A full-stack web application analyzing Vietnam's coffee industry through export data, weather patterns, and production metrics across five major coffee-growing provinces (Đắk Lắk, Gia Lai, Đắk Nông, Kon Tum, Lâm Đồng).

### Tech Stack
- **Backend**: Flask API with SQLAlchemy (Python)
- **Database**: Aiven MySQL (cloud-hosted)
- **Frontend**: Vanilla JavaScript with Chart.js and D3.js
- **Data Collection**: Jupyter notebooks, Selenium web scraping, Open-Meteo API
- **Data Processing**: Pandas with linear interpolation for missing data
## Development Commands

### Environment Setup
```powershell
# Install Python dependencies
pip install -r requirements.txt

# Install Node.js dependencies
npm install

# Set up environment variables
# Copy .env.example to .env and fill in database credentials
```

### Running the Application
```powershell
# Start both API and frontend (recommended)
npm start
# or
npm run dev

# Start API only (Flask backend on default port 5000)
npm run start-api
# or
cd web
python api.py

# Start frontend only (HTTP server on port 8080)
npm run start-frontend
```

### Data Collection & Synchronization
```powershell
# Update weather data from Open-Meteo API (incremental sync)
cd collect_data
python sync_weather.py

# Clear all weather data and re-sync from 2005
python sync_weather.py --clear

# Create/populate production_by_province table
cd web
python create_production_by_province.py
```

### Working with Jupyter Notebooks
```powershell
# Launch Jupyter for data exploration/analysis
jupyter notebook

# Key notebooks:
# - collect_data/main_coffee.ipynb: Main data collection pipeline
# - collect_data/export_api.ipynb: Export data API testing
# - visualize/scatterplot_production.ipynb: Production interpolation method
# - visualize/Time_Series.ipynb: Time series analysis
# - visualize/pair_plot.ipynb: Correlation analysis
```

## Architecture & Code Structure

### Three-Layer Architecture

**1. Data Collection Layer** (`collect_data/`)
- `sync_weather.py`: Automated weather data collector that fetches from Open-Meteo API and stores in MySQL
  - Uses **incremental sync** - automatically continues from last database entry
  - Creates `weather_data_monthly` table with unique constraint on (province, year, month)
  - Fetches data in yearly chunks to avoid API limits
- Jupyter notebooks handle one-time data collection from web sources
- Uses Selenium for scraping when needed

**2. API Layer** (`web/api.py`)
- Flask RESTful API with multiple endpoints for weather, export, and production data
- **Key Pattern**: All endpoints use SQLAlchemy with parameterized queries for security
- **Missing Data Handling**: Pandas `interpolate(method='linear', limit_direction='both')` applied server-side
- Province name mapping: Database uses `DakLak`, `GiaLai` format; API returns Vietnamese names (Đắk Lắk, Gia Lai)
- Export forecasting uses exponential smoothing (Holt's method) for years beyond available data

**3. Frontend Layer** (`web/`)
- `index.html`: Single-page application with section-based navigation
- `script.js`: Handles all API calls, chart rendering (Chart.js/D3), and user interactions
- `styles.css`: Custom styling with split hero layout and responsive design

### Database Schema

**Four Main Tables** (all in Aiven MySQL):

1. `weather_data_monthly`
   - Columns: province, year, month, temperature_mean, precipitation_sum, humidity_mean
   - Unique constraint: (province, year, month)
   - Data source: Open-Meteo API via sync_weather.py

2. `export_country`
   - Columns: year, partner (country), quantity (tons), trade_value_1000usd
   - Contains historical export data by country and year
   - Includes 'World' aggregate rows

3. `production`
   - Columns: year, area_thousand_ha, output_tons, export_tons
   - National-level production data
   - Some years have NULL values handled by interpolation

4. `production_by_province`
   - Columns: province, year, area_thousand_ha, output_tons, export_tons
   - Provincial-level data generated by `create_production_by_province.py`
   - Intentionally includes missing data for 2005-2006 for some provinces (realistic scenario)

### Critical Design Patterns

**Missing Data Strategy**
The codebase uses a consistent approach for handling NULL/missing values:
- Server-side: `df[cols].interpolate(method='linear', limit_direction='both')` in API endpoints
- This matches the methodology established in `visualize/scatterplot_production.ipynb`
- Never use forward-fill or back-fill alone - always use bidirectional linear interpolation

**Database Connection Pattern**
```python
# Always use with context manager
with engine.connect() as conn:
    result = conn.execute(text(query), params)
    conn.commit()  # Only for INSERT/UPDATE/DELETE
```

**Province Name Handling**
```python
# Database format: DakLak, GiaLai, DakNong, KonTum, LamDong (no spaces/diacritics)
# Display format: Đắk Lắk, Gia Lai, Đắk Nông, Kon Tum, Lâm Đồng
# Always use PROVINCE_NAMES mapping dict in api.py
```

**API Response Format**
All API endpoints return JSON with consistent structure:
```json
{
  "success": true,
  "data": [...],
  "stats": {...},
  "count": 123,
  "updated": "ISO-8601-timestamp"
}
```

### Environment Variables (.env)

Required variables (see `.env.example` for full template):
- `HOST`, `PORT`, `USER`, `PASSWORD`, `DB` - Aiven MySQL credentials
- `CA_CERT` or `CA_PEM` - SSL certificate (though currently using `ssl_disabled=true`)
- `CSV_PATH`, `CSV_PATH_MT` - Paths to local CSV data files (for notebooks)

**Security Note**: Never commit `.env` file. It's already in `.gitignore`.

## API Endpoints Reference

### Weather Endpoints
- `GET /api/weather/province/<province>?year=2024&aggregate=monthly|yearly|recent12`
- `GET /api/weather/provinces` - List all provinces
- `GET /api/weather/summary` - Weather summary for all provinces

### Export Endpoints
- `GET /api/exports/top-countries?year=2024` - Top 9 importing countries (with forecasting)
- `GET /api/exports/years` - Available years in export data

### Production Endpoints
- `GET /api/production` - National production data with interpolation
- `GET /api/production/province/<province>` - Provincial production data with interpolation

Valid province values: `DakLak`, `GiaLai`, `DakNong`, `KonTum`, `LamDong` (case-sensitive)

## Common Workflows

### Adding a New API Endpoint
1. Add route decorator and function in `web/api.py`
2. Use `text()` wrapper for SQL queries with parameterized queries (`:param_name`)
3. Apply interpolation to numeric columns if needed: `df[cols].interpolate(method='linear', limit_direction='both')`
4. Return JSON with consistent structure (success, data, count, updated)
5. Update frontend in `web/script.js` to call new endpoint
6. Add chart rendering logic if visualizing data

### Modifying Database Schema
1. Update table creation SQL in relevant script (`sync_weather.py` or `create_production_by_province.py`)
2. Test locally first before running on production Aiven database
3. Update corresponding API endpoint to handle new columns
4. Verify interpolation logic still works correctly

### Debugging Data Collection
- Check `sync_weather.py` for incremental sync logic - it uses `get_last_month_in_db()` to determine starting point
- Weather API has rate limits - script fetches in yearly chunks to avoid issues
- If data looks wrong, use `--clear` flag to wipe and re-sync from 2005

### Working with Forecasting
- Forecasting logic is in `forecast_export_data()` and `exponential_smoothing_forecast()` functions
- Uses Holt's linear trend method with alpha=0.3, beta=0.1
- Forecasts are triggered automatically when requested year > max available year
- Response includes `is_forecast: true` flag to distinguish from actual data

## Code Conventions

### Python
- Use SQLAlchemy `text()` for all raw SQL queries
- Always use context managers (`with engine.connect() as conn:`)
- Pandas DataFrames are the standard for data manipulation
- Use `pd.to_numeric(errors='coerce')` before interpolation
- F-strings for string formatting

### JavaScript
- Vanilla JS (no framework) - keep it simple
- Async/await for API calls
- Chart.js for most visualizations, D3.js for specialized charts
- Use `fetch()` API for AJAX requests

### Database
- Table names: lowercase with underscores (`weather_data_monthly`, `production_by_province`)
- Column names: lowercase with underscores
- Always add indexes on frequently queried columns (province, year)
- Use UNIQUE constraints to prevent duplicates
- Use `INSERT IGNORE` or `ON DUPLICATE KEY UPDATE` for upserts

## Testing & Validation

No formal test suite currently exists. Manual testing workflow:
1. Start API: `cd web && python api.py`
2. Test endpoints using browser or `test_api.ipynb`
3. Start frontend: `npm run start-frontend`
4. Verify charts render correctly with real data
5. Check browser console for JavaScript errors

## Known Issues & Limitations

- Package.json has typo: `npm run start-api` tries to cd to `wed` instead of `web` (should be fixed)
- SSL is disabled (`ssl_disabled=true`) in database connections - should enable with proper certificate in production
- No automated tests - rely on manual testing
- Weather data sync requires manual execution - could be automated with cron/scheduler
- Frontend is not responsive on mobile devices (desktop-first design)

## Performance Considerations

- Weather data API calls can be slow for large date ranges - use yearly chunks
- Database queries use indexes on (province, year, month) for fast lookups
- Interpolation happens on every API call - consider caching results for frequently accessed data
- Chart.js can slow down with 1000+ data points - consider data aggregation for long time series
