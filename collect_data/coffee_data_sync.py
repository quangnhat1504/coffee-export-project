# sync_coffee.py
# 1 file: CSV -> coffee_long (long format, upsert) -> pivot ra 3 báº£ng domain
import os, sys, math
import pandas as pd
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
from pathlib import Path

# In Unicode Ä‘áº¹p trÃªn Windows (trÃ¡nh lá»—i emoji/Unicode)
try:
    sys.stdout.reconfigure(encoding="utf-8")
except Exception:
    pass

# ===== 0) Load .env =====
# Find .env in parent directory (project root)
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)
HOST = os.getenv("HOST")
PORT = int(os.getenv("PORT", "3306"))
USER = os.getenv("USER")
PASSWORD = os.getenv("PASSWORD")
DB = os.getenv("DB")
CA_CERT = os.getenv("CA_CERT")  # Changed from CA_PEM to CA_CERT

if not all([HOST, PORT, USER, PASSWORD, DB]):
    raise SystemExit("Missing env vars. Set HOST, PORT, USER, PASSWORD, DB in .env")

# ===== 1) Káº¿t ná»‘i MySQL (Support both SSL and non-SSL) =====
url = f"mysql+pymysql://{USER}:{PASSWORD}@{HOST}:{PORT}/{DB}"

# Try SSL first, fallback to non-SSL if certificate not available
try:
    if CA_CERT and CA_CERT.strip():
        # Create temp cert file for SSL connection
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.pem') as f:
            f.write(CA_CERT)
            cert_file = f.name
        
        engine = create_engine(
            url,
            connect_args={"ssl": {"ca": cert_file}},
            pool_pre_ping=True,
            pool_recycle=1800,
        )
        print("âœ… Connected with SSL")
    else:
        raise Exception("No SSL certificate provided")
except Exception as e:
    print(f"âš ï¸ SSL connection failed ({e}), trying without SSL...")
    engine = create_engine(
        url + "?ssl_disabled=true",
        pool_pre_ping=True,
        pool_recycle=1800,
    )
    print("âœ… Connected without SSL")

# ===== 2) Äá»c CSV =====
# Use relative paths from current script location
script_dir = os.path.dirname(os.path.abspath(__file__))
CSV_PATH = os.path.join(script_dir, "Data_coffee.csv")
CSV_PATH_MT = os.path.join(script_dir, "Thi_phan_3_thi_truong_chinh.csv")

print(f"ðŸ“ Looking for CSV files in: {script_dir}")
print(f"ðŸ“„ Main CSV: {CSV_PATH}")
print(f"ðŸ“„ Market CSV: {CSV_PATH_MT}")

if not os.path.exists(CSV_PATH):
    raise SystemExit(f"âŒ Data_coffee.csv not found at: {CSV_PATH}")
if not os.path.exists(CSV_PATH_MT):
    raise SystemExit(f"âŒ Thi_phan_3_thi_truong_chinh.csv not found at: {CSV_PATH_MT}")

df = pd.read_csv(CSV_PATH, encoding="utf-8-sig")

# ===== 2b) Äá»c CSV thá»‹ trÆ°á»ng ('.' lÃ  tháº­p phÃ¢n) =====
mt = pd.read_csv(CSV_PATH_MT, encoding="utf-8-sig")

# LÃ m sáº¡ch cá»™t
mt = mt.rename(columns=lambda c: str(c).strip())
if "Unnamed: 0" in mt.columns:
    mt = mt.drop(columns=["Unnamed: 0"])

# Báº¯t buá»™c pháº£i cÃ³ cÃ¡c cá»™t sau (Ä‘Ãºng tÃªn trong file cá»§a báº¡n)
required_cols = {"Year", "Importer", "Trade Value(million_USD)", "Quantity(tons)"}
missing = required_cols - set(mt.columns)
if missing:
    raise SystemExit(f"Thi_phan_3_thi_truong_chinh.csv thiáº¿u cá»™t: {missing}")

# Chuáº©n hoÃ¡ kiá»ƒu dá»¯ liá»‡u
mt["Importer"] = mt["Importer"].astype(str).str.strip()
mt["Year"] = pd.to_numeric(mt["Year"], errors="coerce").astype("Int64")
mt["Trade Value(million_USD)"] = pd.to_numeric(mt["Trade Value(million_USD)"], errors="coerce")
mt["Quantity(tons)"] = pd.to_numeric(mt["Quantity(tons)"], errors="coerce")

mt = mt.dropna(subset=["Year", "Importer"]).copy()
mt["Year"] = mt["Year"].astype(int)

# Chuáº©n hoÃ¡ tÃªn cá»™t Ä‘Ã­ch (mapping sang tÃªn â€œÄ‘áº¹pâ€ Ä‘á»ƒ Ä‘áº©y vÃ o DB)
mt = mt.rename(columns={
    "Trade Value(million_USD)": "trade_value_million_usd",
    "Quantity(tons)": "quantity_tons"
})[["Importer", "Year", "trade_value_million_usd", "quantity_tons"]]

# ===== 3) Melt wide -> long =====
id_col = "Hang_muc"
year_cols = [c for c in df.columns if str(c).isdigit()]
if not year_cols:
    raise SystemExit("No year columns detected in CSV header.")
long_df = df.melt(id_vars=[id_col], value_vars=year_cols, var_name="year", value_name="value")
long_df = long_df.rename(columns={id_col: "hang_muc"})

# ===== 4) Clean =====
long_df["year"]  = pd.to_numeric(long_df["year"], errors="coerce").astype("Int64")
long_df["value"] = pd.to_numeric(long_df["value"], errors="coerce")
long_df = long_df.dropna(subset=["year"]).copy()
long_df["year"] = long_df["year"].astype(int)

# chuáº©n hoÃ¡ nhÃ£n
long_df["hang_muc"] = long_df["hang_muc"].astype(object)          # giá»¯ None/str
long_df = long_df[long_df["hang_muc"].notna()]
long_df["hang_muc"] = long_df["hang_muc"].map(lambda s: str(s).strip())

# loáº¡i nhÃ£n rÃ¡c
bad_labels = {"nan", "NaN", "hang_muc", "Hang_muc", ""}
long_df = long_df[~long_df["hang_muc"].isin(bad_labels)]

# loáº¡i dÃ²ng header láº·p: value == year (vd 2005)
long_df = long_df[~(long_df["value"].notna() & (long_df["value"] == long_df["year"]))]

# dedup trong dataframe
long_df = long_df.drop_duplicates(subset=["hang_muc", "year"], keep="first").reset_index(drop=True)

# NaN -> None (Ä‘á»ƒ MySQL nháº­n NULL)
long_df["value"] = long_df["value"].astype(object)
long_df.loc[pd.isna(long_df["value"]), "value"] = None

# ===== 5) DDL cÃ¡c báº£ng =====
ddl_coffee_long = """
CREATE TABLE IF NOT EXISTS coffee_long (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  hang_muc VARCHAR(255) NOT NULL,
  year INT NOT NULL,
  value DECIMAL(18,4) NULL,
  UNIQUE KEY uniq_hangmuc_year (hang_muc, year)
) CHARACTER SET utf8mb4;
"""

ddl_weather = """
CREATE TABLE IF NOT EXISTS weather (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  year INT NOT NULL,
  temperature DECIMAL(5,2) NULL,
  humidity    DECIMAL(5,2) NULL,
  rain        DECIMAL(10,1) NULL,
  UNIQUE KEY uq_weather_year (year)
) CHARACTER SET utf8mb4;
"""

ddl_production = """
CREATE TABLE IF NOT EXISTS production (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  year INT NOT NULL,
  area_thousand_ha DECIMAL(10,1) NULL,
  output_tons      DECIMAL(14,2) NULL,
  export_tons      DECIMAL(14,2) NULL,
  UNIQUE KEY uq_prod_year (year)
) CHARACTER SET utf8mb4;
"""

ddl_export = """
CREATE TABLE IF NOT EXISTS coffee_export (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  year INT NOT NULL,
  export_value_million_usd        DECIMAL(16,2) NULL,
  price_world_usd_per_ton DECIMAL(12,2) NULL,
  price_vn_usd_per_ton    DECIMAL(12,2) NULL,
  UNIQUE KEY uq_trade_year (year)
) CHARACTER SET utf8mb4;
"""

ddl_market_trade = """
CREATE TABLE IF NOT EXISTS market_trade (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  importer VARCHAR(100) NOT NULL,
  year INT NOT NULL,
  trade_value_million_usd DECIMAL(16,2) NULL,
  quantity_tons           DECIMAL(16,2) NULL,
  UNIQUE KEY uq_importer_year (importer, year)
) CHARACTER SET utf8mb4;
"""

# ===== 6) UPSERT coffee_long =====
upsert_sql = """
INSERT INTO coffee_long (hang_muc, year, value)
VALUES (%s, %s, %s)
ON DUPLICATE KEY UPDATE value = VALUES(value);
"""

def none_if_nan(v):
    if v is None:
        return None
    if isinstance(v, float) and math.isnan(v):
        return None
    return v

rows = [(str(hm), int(y), none_if_nan(v)) for hm, y, v in long_df[["hang_muc","year","value"]].itertuples(index=False, name=None)]

with engine.begin() as conn:
    #xoad báº£ng náº¿u cÃ³
    conn.execute(text("DROP TABLE IF EXISTS weather"))
    conn.execute(text("DROP TABLE IF EXISTS production"))
    conn.execute(text("DROP TABLE IF EXISTS coffee_export"))
    conn.execute(text("DROP TABLE IF EXISTS market_trade"))
    conn.execute(text("DROP TABLE IF EXISTS coffee_long"))

    # táº¡o báº£ng
    conn.execute(text(ddl_coffee_long))
    conn.execute(text(ddl_weather))
    conn.execute(text(ddl_production))
    conn.execute(text(ddl_export))
    conn.execute(text(ddl_market_trade))


    # upsert coffee_long (raw cursor cho executemany nhanh)
    if rows:
        raw = conn.connection
        with raw.cursor() as cur:
            cur.executemany(upsert_sql, rows)

    # ===== 7) Pivot sang 3 báº£ng domain =====
    # a) weather
    conn.execute(text("""
        INSERT INTO weather (year, temperature, humidity, rain)
        SELECT y.year,
               MAX(CASE WHEN c.hang_muc LIKE 'Nhiet_do_trung_binh%' THEN c.value END) AS temperature,
               MAX(CASE WHEN c.hang_muc LIKE 'Do_am_trung_binh%'   THEN c.value END) AS humidity,
               MAX(CASE WHEN c.hang_muc LIKE 'Tong_luong_mua%'     THEN c.value END) AS rain
        FROM (SELECT DISTINCT year FROM coffee_long) y
        LEFT JOIN coffee_long c ON c.year = y.year
        GROUP BY y.year
        ON DUPLICATE KEY UPDATE
          temperature = VALUES(temperature),
          humidity    = VALUES(humidity),
          rain        = VALUES(rain);
    """))

    # b) production
    conn.execute(text("""
        INSERT INTO production (year, area_thousand_ha, output_tons, export_tons)
        SELECT y.year,
               MAX(CASE WHEN c.hang_muc LIKE 'Area (Thousand ha)%'         THEN c.value END) AS area_thousand_ha,
               MAX(CASE WHEN c.hang_muc LIKE 'San luong ca phe san xuat%'  THEN c.value END) AS output_tons,
               MAX(CASE WHEN c.hang_muc LIKE 'San luong ca phe xuat khau%' THEN c.value END) AS export_tons
        FROM (SELECT DISTINCT year FROM coffee_long) y
        LEFT JOIN coffee_long c ON c.year = y.year
        GROUP BY y.year
        ON DUPLICATE KEY UPDATE
          area_thousand_ha = VALUES(area_thousand_ha),
          output_tons      = VALUES(output_tons),
          export_tons      = VALUES(export_tons);
    """))

    # c) coffee_export
    conn.execute(text("""
        INSERT INTO coffee_export (year, export_value_million_usd, price_world_usd_per_ton, price_vn_usd_per_ton)
        SELECT y.year,
               MAX(CASE 
                     WHEN c.hang_muc LIKE 'Kim_Ngach(millionUSD)%'
                          OR c.hang_muc LIKE 'Kim Ngach%'
                          OR c.hang_muc LIKE 'Kim_Ngach%'
                     THEN c.value 
                   END) AS export_value_million_usd,
               MAX(CASE WHEN c.hang_muc LIKE 'coffee_price_usd_per_ton(world)%'   THEN c.value END) AS price_world_usd_per_ton,
               MAX(CASE WHEN c.hang_muc LIKE 'coffee_price_usd_per_ton(vietnam)%' THEN c.value END) AS price_vn_usd_per_ton
        FROM (SELECT DISTINCT year FROM coffee_long) y
        LEFT JOIN coffee_long c ON c.year = y.year
        GROUP BY y.year
        ON DUPLICATE KEY UPDATE
          export_value_million_usd = VALUES(export_value_million_usd),
          price_world_usd_per_ton  = VALUES(price_world_usd_per_ton),
          price_vn_usd_per_ton     = VALUES(price_vn_usd_per_ton);
    """))

    # d) market_trade: upsert tá»« mt
    upsert_mt_sql = """
        INSERT INTO market_trade
          (importer, year, trade_value_million_usd, quantity_tons)
        VALUES (%s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE
          trade_value_million_usd = VALUES(trade_value_million_usd),
          quantity_tons           = VALUES(quantity_tons);
    """
    mt_rows = [
        (str(row.Importer), int(row.Year),
         None if pd.isna(row.trade_value_million_usd) else float(row.trade_value_million_usd),
         None if pd.isna(row.quantity_tons) else float(row.quantity_tons))
        for row in mt.itertuples(index=False)
    ]
    if mt_rows:
        raw3 = conn.connection
        with raw3.cursor() as cur:
            cur.executemany(upsert_mt_sql, mt_rows)


    # ===== 8) Report nhanh =====
    total_long = conn.execute(text("SELECT COUNT(*) FROM coffee_long")).scalar()
    total_w    = conn.execute(text("SELECT COUNT(*) FROM weather")).scalar()
    total_p    = conn.execute(text("SELECT COUNT(*) FROM production")).scalar()
    total_e    = conn.execute(text("SELECT COUNT(*) FROM coffee_export")).scalar()
    print(f"coffee_long rows: {total_long}")
    print(f"weather rows:     {total_w}")
    print(f"production rows:  {total_p}")
    print(f"coffee_export rows:{total_e}")

    print("\nSample weather:")
    for r in conn.execute(text("SELECT * FROM weather ORDER BY year LIMIT 5")):
        print(r)
    
    total_mt = conn.execute(text("SELECT COUNT(*) FROM market_trade")).scalar()
    print(f"market_trade rows:  {total_mt}")
    print("\nSample market_trade:")
    for r in conn.execute(text("SELECT * FROM market_trade ORDER BY year, importer LIMIT 5")):
        print(r)


